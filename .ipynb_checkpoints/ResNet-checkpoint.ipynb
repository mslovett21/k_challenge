{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_fingerprints_fh = 'sample/sample_fingerprints.csv'\n",
    "drug_targets_fh      = 'sample/sample_targets.csv'\n",
    "drug_weights_fh      = 'sample/sample_weights.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size       = 10000\n",
    "fingerprint_size  = 1024\n",
    "fingerprint_width = 32\n",
    "targets_num       = 420\n",
    "weights_num       = 420\n",
    "num_channels      = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def populate_data(file_handle,data_matrix, data_size):\n",
    "    with open(file_handle) as fh:\n",
    "        j=0\n",
    "        content = fh.readlines()\n",
    "        content = [x.strip() for x in content]\n",
    "        for line in content:\n",
    "            result = re.split(r'[,\\t]\\s*',line)\n",
    "            for i in range(1,data_size+1):\n",
    "                data_matrix[j][i-1] = np.float32(result[i])\n",
    "            j = j+1\n",
    "    print(j)\n",
    "    fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_fingerprints = []\n",
    "drug_targets      = []\n",
    "drug_weights      = []\n",
    "\n",
    "\n",
    "for i in range(sample_size):\n",
    "    fingerprint_holder = [0]* fingerprint_size\n",
    "    drug_fingerprints.append(fingerprint_holder)\n",
    "    \n",
    "for i in range(sample_size):\n",
    "    target_holder = [0]* targets_num\n",
    "    drug_targets.append(target_holder)\n",
    "\n",
    "for i in range(sample_size):\n",
    "    weight_holder = [0]* weights_num\n",
    "    drug_weights.append(weight_holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "populate_data(drug_weights_fh, drug_weights, weights_num)\n",
    "populate_data(drug_targets_fh, drug_targets, targets_num)\n",
    "populate_data(drug_fingerprints_fh, drug_fingerprints, fingerprint_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_fingerprints = np.array(drug_fingerprints)\n",
    "drug_targets      = np.array(drug_targets)\n",
    "drug_weights      = np.array(drug_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gist.github.com/mjdietzx/0cb95922aac14d446a6530f87b3a04ce#file-residual_network-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tensorflow/tpu/blob/master/models/official/resnet/resnet_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **TensorFlow** graph consists of the following parts:\n",
    "\n",
    "* **Placeholder** variables used for inputting data to the graph.\n",
    "* **Variables** that are going to be optimized so as to make the convolutional network perform better.\n",
    "* The mathematical formulas for the convolutional network.\n",
    "* **Cost function** be used to guide the optimization of the variables.\n",
    "* **Optimization** method which updates the variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, fingerprint_size],name = \"In_Flat_Drug_Fingerprint\")\n",
    "\n",
    "drug_image = tf.reshape(x, [-1, fingerprint_width, fingerprint_width, num_channels], name=\"Drug_Image_32x32\")\n",
    "\n",
    "inputs = tf.transpose(drug_image, [0, 3, 1, 2])\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, targets_num],name='True_Labels')\n",
    "\n",
    "cross_entropy_weights = tf.placeholder(tf.float32, [None, weights_num],name = \"Cross_Entropy_Weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05), name=\"Weights\")\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]), name=\"Biases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK ARCHITECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/ResNetPic.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Description\n",
    "*  **conv1** (7x7 conv, 64,/2) -> ***filter_size***=7, ***out_channels***=64, ***stride***=2\n",
    "*  **pooling layer** ***stride***=2\n",
    "*  **block1** layers 6x[(3x3 con,64,)] -> 6 conv layers with:    ***filter_size***=3, ***out_channels***=64, ***stride***=1\n",
    "*  **block2** layers 8x[(3x3 con,128,)] -> 8 conv layers with:   ***filter_size***=3, ***out_channels***=128, ***stride***=1\n",
    "*  **block3** layers 12x[(3x3 con,256,)] -> 12 conv layers with: ***filter_size***=3, ***out_channels***=265, ***stride***=1 \n",
    "*  **block4** layers 6x[(3x3 con,512,)] -> 6 conv layers with:   ***filter_size***=3, ***out_channels***=512, ***stride***=1\n",
    "* **average pooling**\n",
    "* **fully connected layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difficulty: Shortcut Connection (FIRST OROGINAL IMPLEMENTATION)\n",
    "The identity shortcuts can be directly used when the input and output are of the same dimensions (solid line shortcuts on the graph above). When the dimension increase, we have two options:\n",
    "<br>\n",
    "* (A) the shortcut still performs identity mapping with extra zero passed for increasing dimensions,\n",
    "* (B) the shortcut is used to match dimensions (done by 1x1 convolution)\n",
    "<br>\n",
    "<br>\n",
    "For both options, when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/better_residue.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/two_res_unit.png\" alt=\"Drawing2\" style=\"width:300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HELPERS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_padding(inputs, kernel_size, data_format):\n",
    "    \n",
    "    pad_total = kernel_size - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "    \n",
    "    if data_format == 'channels_first':\n",
    "        padded_inputs = tf.pad(inputs, [[0, 0], [0, 0],[pad_beg, pad_end], [pad_beg, pad_end]])\n",
    "    else:\n",
    "        padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n",
    "                                    [pad_beg, pad_end], [0, 0]])\n",
    "    return padded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_fixed_padding(inputs, filters, kernel_size, strides, data_format):\n",
    "    \n",
    "    if strides > 1:\n",
    "        inputs = fixed_padding(inputs, kernel_size, data_format)\n",
    "        \n",
    "    return tf.layers.conv2d(inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "                            padding=('SAME' if strides == 1 else 'VALID'), use_bias=False,\n",
    "                            kernel_initializer=tf.variance_scaling_initializer(), data_format=data_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_NORM_DECAY = 0.9\n",
    "BATCH_NORM_EPSILON = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm_relu(inputs, is_training, relu=True, init_zero=False, data_format='channels_first'):\n",
    "    if init_zero:\n",
    "        gamma_initializer = tf.zeros_initializer()\n",
    "    else:\n",
    "        gamma_initializer = tf.ones_initializer()\n",
    "        \n",
    "    axis = 3\n",
    "    inputs = tf.layers.batch_normalization(inputs=inputs, axis=axis, momentum=BATCH_NORM_DECAY,\n",
    "                                           epsilon=BATCH_NORM_EPSILON, center=True, scale=True, \n",
    "                                           training=is_training,fused=True, gamma_initializer=gamma_initializer)\n",
    "    if relu:\n",
    "        inputs = tf.nn.relu(inputs) \n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORIGINAL IMPLEMENTATION OF THE RESIDUAL UNIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_unit(inputs, filters, is_training, strides,\n",
    "                   use_projection=False, data_format='channels_first'):\n",
    "    shortcut = inputs\n",
    "    print(\"Residue unit:\")\n",
    "    if use_projection:\n",
    "        shortcut = conv2d_fixed_padding(\n",
    "        inputs=inputs, filters=filters, kernel_size=1, strides=strides,\n",
    "        data_format=data_format)\n",
    "        print(\"FIRST IN THE BLOCK\")\n",
    "    shortcut = batch_norm_relu(shortcut, is_training, relu=False,\n",
    "                               data_format=data_format)\n",
    "    print(\"Shortcut:\")\n",
    "    print(shortcut)\n",
    "    print(\"CONV 1\")\n",
    "    inputs = conv2d_fixed_padding(\n",
    "      inputs=inputs, filters=filters, kernel_size=3, strides=strides,\n",
    "      data_format=data_format)\n",
    "\n",
    "    print(inputs)\n",
    "    print(\"\\n\")\n",
    "    inputs = batch_norm_relu(inputs, is_training, data_format=data_format)\n",
    "    print(\"CONV 2\")\n",
    "    \n",
    "    inputs = conv2d_fixed_padding(\n",
    "      inputs=inputs, filters=filters, kernel_size=3, strides=1,\n",
    "      data_format=data_format)\n",
    "    print(inputs)\n",
    "    print(\"\\n\") \n",
    "    inputs = batch_norm_relu(inputs, is_training, relu=False, init_zero=True,\n",
    "                           data_format=data_format)\n",
    "    \n",
    "    print(\"Added Shortcut: \")\n",
    "    sum_with_shortcut = inputs + shortcut\n",
    "    print(sum_with_shortcut)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return tf.nn.relu( sum_with_shortcut )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_group(inputs, filters, blocks, strides, is_training, name,data_format='channels_first'):\n",
    "    \n",
    "    inputs = residual_unit(inputs, filters, is_training, strides,\n",
    "                    use_projection=True, data_format=data_format)\n",
    "    \n",
    "    for _ in range(1, blocks):\n",
    "        inputs = residual_unit(inputs, filters, is_training, 1,\n",
    "                      data_format=data_format)\n",
    "\n",
    "    return tf.identity(inputs, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input, num_inputs,num_outputs): \n",
    "\n",
    "    # new weights and biases for the layer\n",
    "    weights = new_weights(shape = [num_inputs, num_outputs])\n",
    "    biases = new_biases(length = num_outputs)\n",
    "\n",
    "    # calculate the layer as the matrix multiplication of the input and weights, and then add the bias-values.\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    \n",
    "    layer = tf.nn.sigmoid(layer,name = \"FULLY_CONNECTED_WITH_SIGMOID\")\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Architecture of 34-layer residual neural network:\n",
    "*  **conv1** (7x7 conv, 64,/2) -> ***filter_size***=7, ***out_channels***=64, ***stride***=2\n",
    "*  **pooling layer** ***stride***=2\n",
    "*  **block1** layers 6x[(3x3 con,64,)] -> 6 conv layers with:    ***filter_size***=3, ***out_channels***=64, ***stride***=1\n",
    "*  **block2** layers 8x[(3x3 con,128,)] -> 8 conv layers with:   ***filter_size***=3, ***out_channels***=128, ***stride***=1\n",
    "*  **block3** layers 12x[(3x3 con,256,)] -> 12 conv layers with: ***filter_size***=3, ***out_channels***=265, ***stride***=1 \n",
    "*  **block4** layers 6x[(3x3 con,512,)] -> 6 conv layers with:   ***filter_size***=3, ***out_channels***=512, ***stride***=1\n",
    "* **average pooling**\n",
    "* **fully connected layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETERS OF THE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training          = True\n",
    "data_format          = 'channels_first'\n",
    "filter_size_par      = 3\n",
    "num_classes          = 420\n",
    "\n",
    "block_1_filters      = 64\n",
    "num_blocks_1         = 3\n",
    "\n",
    "block_2_filters      = 128\n",
    "num_blocks_2         = 4\n",
    "\n",
    "block_3_filters      = 256\n",
    "num_blocks_3         = 6\n",
    "\n",
    "block_4_filters      = 512\n",
    "num_blocks_4         = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT\n",
    "**Image** of shape `num_channels` by`fingerprint_size` by `fingerprint_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.transpose(drug_image, [0, 3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0217 16:27:12.649718 140472112686912 deprecation.py:323] From <ipython-input-19-8118a9c6bcfc>:1: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.layers.Conv2D instead.\n",
      "W0217 16:27:12.653642 140472112686912 deprecation.py:506] From /home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1253: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d/BiasAdd:0' shape=(?, 64, 13, 13) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = tf.layers.conv2d(inputs=inputs, filters= 64 , kernel_size= 7,strides= 2 , data_format=data_format)\n",
    "#conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=7, strides=(2, 2), padding='valid', data_format=data_format)\n",
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0217 16:27:16.657805 140472112686912 deprecation.py:323] From <ipython-input-13-bacda41f7835>:10: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 64, 13, 13) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = batch_norm_relu(conv1, is_training=is_training, data_format='channels_first')\n",
    "#conv1 = tf.keras.layers.BatchNormalization(axis=1, momentum=0.99, epsilon=0.001)\n",
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0217 16:27:16.818209 140472112686912 deprecation.py:323] From <ipython-input-21-f09655247164>:1: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'max_pooling2d/MaxPool:0' shape=(?, 64, 7, 7) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling_layer = tf.layers.max_pooling2d(inputs=conv1, pool_size=3,strides=2, padding='SAME',data_format='channels_first')\n",
    "#pooling_layer = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding='SAME', data_format='channels_first')\n",
    "pooling_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 1\n",
    "layers 6x[(3x3 con,64,)] -> 6 conv layers with:    ***filter_size***=3, ***out_channels***=64, \n",
    "<br>\n",
    "or 3 times residual unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residue unit:\n",
      "FIRST IN THE BLOCK\n",
      "Shortcut:\n",
      "Tensor(\"batch_normalization_1/FusedBatchNorm:0\", shape=(?, 64, 7, 7), dtype=float32)\n",
      "CONV 1\n",
      "Tensor(\"conv2d_2/Conv2D:0\", shape=(?, 64, 7, 7), dtype=float32)\n",
      "\n",
      "\n",
      "CONV 2\n",
      "Tensor(\"conv2d_3/Conv2D:0\", shape=(?, 64, 7, 7), dtype=float32)\n",
      "\n",
      "\n",
      "Added Shortcut: \n",
      "Tensor(\"add:0\", shape=(?, 64, 7, 7), dtype=float32)\n",
      "\n",
      "\n",
      "Residue unit:\n",
      "Shortcut:\n",
      "Tensor(\"batch_normalization_4/FusedBatchNorm:0\", shape=(?, 64, 7, 7), dtype=float32)\n",
      "CONV 1\n",
      "Tensor(\"conv2d_4/Conv2D:0\", shape=(?, 64, 7, 7), dtype=float32)\n",
      "\n",
      "\n",
      "CONV 2\n",
      "Tensor(\"conv2d_5/Conv2D:0\", shape=(?, 64, 7, 7), dtype=float32)\n",
      "\n",
      "\n",
      "Added Shortcut: \n",
      "Tensor(\"add_1:0\", shape=(?, 64, 7, 7), dtype=float32)\n",
      "\n",
      "\n",
      "Residue unit:\n",
      "Shortcut:\n",
      "Tensor(\"batch_normalization_7/FusedBatchNorm:0\", shape=(?, 64, 7, 7), dtype=float32)\n",
      "CONV 1\n",
      "Tensor(\"conv2d_6/Conv2D:0\", shape=(?, 64, 7, 7), dtype=float32)\n",
      "\n",
      "\n",
      "CONV 2\n",
      "Tensor(\"conv2d_7/Conv2D:0\", shape=(?, 64, 7, 7), dtype=float32)\n",
      "\n",
      "\n",
      "Added Shortcut: \n",
      "Tensor(\"add_2:0\", shape=(?, 64, 7, 7), dtype=float32)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "block1= block_group(inputs=pooling_layer, filters=block_1_filters , blocks=num_blocks_1,strides=1, is_training=is_training,\n",
    "                      name='BLOCK_1',data_format=data_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 2\n",
    "layers 8x[(3x3 con,128,)] -> 8 conv layers with:    ***filter_size***=3, ***out_channels***=128, \n",
    "<br>\n",
    "or 4 times residual unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residue unit:\n",
      "FIRST IN THE BLOCK\n",
      "Shortcut:\n",
      "Tensor(\"batch_normalization_10/FusedBatchNorm:0\", shape=(?, 128, 4, 4), dtype=float32)\n",
      "CONV 1\n",
      "Tensor(\"conv2d_9/Conv2D:0\", shape=(?, 128, 4, 4), dtype=float32)\n",
      "\n",
      "\n",
      "CONV 2\n",
      "Tensor(\"conv2d_10/Conv2D:0\", shape=(?, 128, 4, 4), dtype=float32)\n",
      "\n",
      "\n",
      "Added Shortcut: \n",
      "Tensor(\"add_3:0\", shape=(?, 128, 4, 4), dtype=float32)\n",
      "\n",
      "\n",
      "Residue unit:\n",
      "Shortcut:\n",
      "Tensor(\"batch_normalization_13/FusedBatchNorm:0\", shape=(?, 128, 4, 4), dtype=float32)\n",
      "CONV 1\n",
      "Tensor(\"conv2d_11/Conv2D:0\", shape=(?, 128, 4, 4), dtype=float32)\n",
      "\n",
      "\n",
      "CONV 2\n",
      "Tensor(\"conv2d_12/Conv2D:0\", shape=(?, 128, 4, 4), dtype=float32)\n",
      "\n",
      "\n",
      "Added Shortcut: \n",
      "Tensor(\"add_4:0\", shape=(?, 128, 4, 4), dtype=float32)\n",
      "\n",
      "\n",
      "Residue unit:\n",
      "Shortcut:\n",
      "Tensor(\"batch_normalization_16/FusedBatchNorm:0\", shape=(?, 128, 4, 4), dtype=float32)\n",
      "CONV 1\n",
      "Tensor(\"conv2d_13/Conv2D:0\", shape=(?, 128, 4, 4), dtype=float32)\n",
      "\n",
      "\n",
      "CONV 2\n",
      "Tensor(\"conv2d_14/Conv2D:0\", shape=(?, 128, 4, 4), dtype=float32)\n",
      "\n",
      "\n",
      "Added Shortcut: \n",
      "Tensor(\"add_5:0\", shape=(?, 128, 4, 4), dtype=float32)\n",
      "\n",
      "\n",
      "Residue unit:\n",
      "Shortcut:\n",
      "Tensor(\"batch_normalization_19/FusedBatchNorm:0\", shape=(?, 128, 4, 4), dtype=float32)\n",
      "CONV 1\n",
      "Tensor(\"conv2d_15/Conv2D:0\", shape=(?, 128, 4, 4), dtype=float32)\n",
      "\n",
      "\n",
      "CONV 2\n",
      "Tensor(\"conv2d_16/Conv2D:0\", shape=(?, 128, 4, 4), dtype=float32)\n",
      "\n",
      "\n",
      "Added Shortcut: \n",
      "Tensor(\"add_6:0\", shape=(?, 128, 4, 4), dtype=float32)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "block2 = block_group(inputs=block1, filters=block_2_filters , blocks=num_blocks_2, strides=2, is_training=is_training,\n",
    "                      name='BLOCK_2',data_format=data_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 3\n",
    "layers 12 x[(3x3 con,256,)] -> 12 conv layers with:    ***filter_size***=3, ***out_channels***=256, \n",
    "<br>\n",
    "or 6 times residual unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residue unit:\n",
      "FIRST IN THE BLOCK\n",
      "Shortcut:\n",
      "Tensor(\"batch_normalization_22/FusedBatchNorm:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "CONV 1\n",
      "Tensor(\"conv2d_18/Conv2D:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n",
      "CONV 2\n",
      "Tensor(\"conv2d_19/Conv2D:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Added Shortcut: \n",
      "Tensor(\"add_7:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Residue unit:\n",
      "Shortcut:\n",
      "Tensor(\"batch_normalization_25/FusedBatchNorm:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "CONV 1\n",
      "Tensor(\"conv2d_20/Conv2D:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n",
      "CONV 2\n",
      "Tensor(\"conv2d_21/Conv2D:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Added Shortcut: \n",
      "Tensor(\"add_8:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Residue unit:\n",
      "Shortcut:\n",
      "Tensor(\"batch_normalization_28/FusedBatchNorm:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "CONV 1\n",
      "Tensor(\"conv2d_22/Conv2D:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n",
      "CONV 2\n",
      "Tensor(\"conv2d_23/Conv2D:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Added Shortcut: \n",
      "Tensor(\"add_9:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Residue unit:\n",
      "Shortcut:\n",
      "Tensor(\"batch_normalization_31/FusedBatchNorm:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "CONV 1\n",
      "Tensor(\"conv2d_24/Conv2D:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n",
      "CONV 2\n",
      "Tensor(\"conv2d_25/Conv2D:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Added Shortcut: \n",
      "Tensor(\"add_10:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Residue unit:\n",
      "Shortcut:\n",
      "Tensor(\"batch_normalization_34/FusedBatchNorm:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "CONV 1\n",
      "Tensor(\"conv2d_26/Conv2D:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n",
      "CONV 2\n",
      "Tensor(\"conv2d_27/Conv2D:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Added Shortcut: \n",
      "Tensor(\"add_11:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Residue unit:\n",
      "Shortcut:\n",
      "Tensor(\"batch_normalization_37/FusedBatchNorm:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "CONV 1\n",
      "Tensor(\"conv2d_28/Conv2D:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n",
      "CONV 2\n",
      "Tensor(\"conv2d_29/Conv2D:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Added Shortcut: \n",
      "Tensor(\"add_12:0\", shape=(?, 256, 2, 2), dtype=float32)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "block3 = block_group(inputs=block2, filters=block_3_filters , blocks=num_blocks_3, strides=2, is_training=is_training,\n",
    "                      name='BLOCK_3',data_format=data_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 4 \n",
    "layers 6x[(3x3 con,512,)] -> 6 conv layers with:    ***filter_size***=3, ***out_channels***=512, \n",
    "<br>\n",
    "or  times residual unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residue unit:\n",
      "FIRST IN THE BLOCK\n",
      "Shortcut:\n",
      "Tensor(\"batch_normalization_40/FusedBatchNorm:0\", shape=(?, 512, 1, 1), dtype=float32)\n",
      "CONV 1\n",
      "Tensor(\"conv2d_31/Conv2D:0\", shape=(?, 512, 1, 1), dtype=float32)\n",
      "\n",
      "\n",
      "CONV 2\n",
      "Tensor(\"conv2d_32/Conv2D:0\", shape=(?, 512, 1, 1), dtype=float32)\n",
      "\n",
      "\n",
      "Added Shortcut: \n",
      "Tensor(\"add_13:0\", shape=(?, 512, 1, 1), dtype=float32)\n",
      "\n",
      "\n",
      "Residue unit:\n",
      "Shortcut:\n",
      "Tensor(\"batch_normalization_43/FusedBatchNorm:0\", shape=(?, 512, 1, 1), dtype=float32)\n",
      "CONV 1\n",
      "Tensor(\"conv2d_33/Conv2D:0\", shape=(?, 512, 1, 1), dtype=float32)\n",
      "\n",
      "\n",
      "CONV 2\n",
      "Tensor(\"conv2d_34/Conv2D:0\", shape=(?, 512, 1, 1), dtype=float32)\n",
      "\n",
      "\n",
      "Added Shortcut: \n",
      "Tensor(\"add_14:0\", shape=(?, 512, 1, 1), dtype=float32)\n",
      "\n",
      "\n",
      "Residue unit:\n",
      "Shortcut:\n",
      "Tensor(\"batch_normalization_46/FusedBatchNorm:0\", shape=(?, 512, 1, 1), dtype=float32)\n",
      "CONV 1\n",
      "Tensor(\"conv2d_35/Conv2D:0\", shape=(?, 512, 1, 1), dtype=float32)\n",
      "\n",
      "\n",
      "CONV 2\n",
      "Tensor(\"conv2d_36/Conv2D:0\", shape=(?, 512, 1, 1), dtype=float32)\n",
      "\n",
      "\n",
      "Added Shortcut: \n",
      "Tensor(\"add_15:0\", shape=(?, 512, 1, 1), dtype=float32)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "block4 = block_group(inputs=block3, filters=block_4_filters , blocks=num_blocks_4, strides=2, is_training=is_training,\n",
    "                      name='BLOCK_4',data_format=data_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AVE POOLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0217 16:27:22.584829 140472112686912 deprecation.py:323] From <ipython-input-26-43d2b8365b0d>:4: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.average_pooling2d instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'average_pooling2d/AvgPool:0' shape=(?, 512, 1, 1) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_size = (1, 1)\n",
    "output_ave_pooling = tf.layers.average_pooling2d(\n",
    "    inputs=block4 , pool_size=pool_size, strides=1, padding='VALID',\n",
    "    data_format=data_format)\n",
    "output_ave_pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_flat= tf.reshape(output_ave_pooling, [-1, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer1 = new_fc_layer(input = layer_flat, num_inputs = 512, num_outputs = num_classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf.round(fc_layer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function to Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits = fc_layer1,\n",
    "                                                        labels = y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiply logistic loss with weights (ELEMENT-WISE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of cost for all labels with weight 1\n",
    "cost_sum = tf.reduce_sum(tf.multiply(cross_entropy_weights,cross_entropy))\n",
    "\n",
    "# number of labels with weight 1\n",
    "num_nonzero_weights = tf.count_nonzero(input_tensor=cross_entropy_weights,dtype = tf.float32)\n",
    "\n",
    "# average cost\n",
    "cost = tf.divide(cost_sum, num_nonzero_weights, name= \"COST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0217 16:27:30.524719 140472112686912 deprecation.py:506] From /home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py:187: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0217 16:27:31.583082 140472112686912 deprecation.py:323] From /home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "accuracy, accuracy_ops =tf.metrics.accuracy(labels=y_true,predictions=output, weights = cross_entropy_weights)\n",
    "# Local variables need to show updated accuracy on each iteration \n",
    "stream_vars = [i for i in tf.local_variables()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible fix of a bug for rtx 2070\n",
    "https://github.com/tensorflow/tensorflow/issues/24496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TensorFlow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "session.run(init)\n",
    "saver = tf.train.Saver()\n",
    "train_batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(batch_size, available_indexes):\n",
    "    chosen = np.random.choice(available_indexes,batch_size, replace=False)\n",
    "    available_indexes = set(available_indexes) - set(chosen)\n",
    "    X_batch = drug_fingerprints[chosen, :]\n",
    "    y_batch = drug_targets[chosen, :]\n",
    "    cross_entropy_weights = drug_weights[chosen,:]\n",
    "    return X_batch,y_batch,cross_entropy_weights, list(available_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter for total number of epochs\n",
    "total_epochs = 0\n",
    "\n",
    "def optimize(num_epochs):\n",
    "    \n",
    "    # update the global variable rather than a local copy.\n",
    "    global total_epochs\n",
    "\n",
    "    # start-time \n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(total_epochs, total_epochs + num_epochs):\n",
    "\n",
    "        for j in range(int(len(drug_targets)/train_batch_size)):\n",
    "            if j == 0:\n",
    "                available_indexes = list(range(len(drug_targets)))                         \n",
    "            x_batch,y_true_batch, weights_batch, available_indexes = fetch_batch(train_batch_size, available_indexes)\n",
    "\n",
    "            # put the batch into a dict with the proper names for placeholder variables\n",
    "            feed_dict_train = {x: x_batch,\n",
    "                               y_true: y_true_batch,\n",
    "                              cross_entropy_weights: weights_batch}\n",
    "\n",
    "            # run the optimizer with the btch training data\n",
    "            session.run(optimizer, feed_dict=feed_dict_train)\n",
    "            # save the model's weights at the end of each epoch\n",
    "            saver.save(session, \"./temp/my_model_ResNet.ckpt\")\n",
    "\n",
    "            # print update every 10 iterations\n",
    "            if j % 20 == 0:\n",
    "\n",
    "                # calculate the accuracy on the training-set.\n",
    "                acc_ops = session.run(accuracy_ops, feed_dict=feed_dict_train)\n",
    "\n",
    "                # print update\n",
    "                print('[Total correct, Total count]:',session.run(stream_vars)) \n",
    "                print(\"Epoch: {}, Optimization Iteration (batch #): {}, Training Accuracy: {} \\n\".format(i+1,j+1,acc_ops))                        \n",
    "\n",
    "        # update the total number of iterations\n",
    "    total_epochs += num_epochs\n",
    "\n",
    "    # end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    #time-usage\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d/Conv2D (defined at <ipython-input-19-8118a9c6bcfc>:1) ]]\n\t [[gradients/conv2d_10/Conv2D_grad/ShapeN/_167]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node conv2d/Conv2D:\n transpose_1/perm (defined at <ipython-input-18-02898b0c359a>:1)\t\n Drug_Image_32x32/shape (defined at <ipython-input-8-d74fef467810>:3)\t\n In_Flat_Drug_Fingerprint (defined at <ipython-input-8-d74fef467810>:1)\n\nOriginal stack trace for 'conv2d/Conv2D':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-8118a9c6bcfc>\", line 1, in <module>\n    conv1 = tf.layers.conv2d(inputs=inputs, filters= 64 , kernel_size= 7,strides= 2 , data_format=data_format)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\", line 424, in conv2d\n    return layer.apply(inputs)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1232, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 531, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 565, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 196, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1078, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 634, in __call__\n    return self.call(inp, filter)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 233, in __call__\n    name=self.name)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1708, in conv2d\n    name=name)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1087, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 800, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3473, in create_op\n    op_def=op_def)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1961, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1320\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d/Conv2D}}]]\n\t [[gradients/conv2d_10/Conv2D_grad/ShapeN/_167]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-a894c5f56751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-1367c5ed5f73>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(num_epochs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# run the optimizer with the btch training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;31m# save the model's weights at the end of each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./temp/my_model_ResNet.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 930\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    931\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1153\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1154\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1329\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d/Conv2D (defined at <ipython-input-19-8118a9c6bcfc>:1) ]]\n\t [[gradients/conv2d_10/Conv2D_grad/ShapeN/_167]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node conv2d/Conv2D:\n transpose_1/perm (defined at <ipython-input-18-02898b0c359a>:1)\t\n Drug_Image_32x32/shape (defined at <ipython-input-8-d74fef467810>:3)\t\n In_Flat_Drug_Fingerprint (defined at <ipython-input-8-d74fef467810>:1)\n\nOriginal stack trace for 'conv2d/Conv2D':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-8118a9c6bcfc>\", line 1, in <module>\n    conv1 = tf.layers.conv2d(inputs=inputs, filters= 64 , kernel_size= 7,strides= 2 , data_format=data_format)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\", line 424, in conv2d\n    return layer.apply(inputs)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1232, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 531, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 565, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 196, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1078, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 634, in __call__\n    return self.call(inp, filter)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 233, in __call__\n    name=self.name)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1708, in conv2d\n    name=name)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1087, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 800, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3473, in create_op\n    op_def=op_def)\n  File \"/home/patrycja/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1961, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "optimize(num_epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(\"./logs/ResNet\", session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! tensorboard --logdir=log+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path= saver.save(session, \"./temp/my_model_ResNet_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0-dev20190208\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -c 'import tensorflow as tf; print(tf.__version__)'  # for Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-037c5170842b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
