{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_fingerprints_fh = 'sample/sample_fingerprints.csv'\n",
    "drug_targets_fh      = 'sample/sample_targets.csv'\n",
    "drug_weights_fh      = 'sample/sample_weights.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size       = 10000\n",
    "fingerprint_size  = 1024\n",
    "fingerprint_width = 32\n",
    "targets_num       = 420\n",
    "weights_num       = 420\n",
    "num_channels      = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def populate_data(file_handle,data_matrix, data_size):\n",
    "    with open(file_handle) as fh:\n",
    "        j=0\n",
    "        content = fh.readlines()\n",
    "        content = [x.strip() for x in content]\n",
    "        for line in content:\n",
    "            result = re.split(r'[,\\t]\\s*',line)\n",
    "            for i in range(1,data_size+1):\n",
    "                data_matrix[j][i-1] = np.float32(result[i])\n",
    "            j = j+1\n",
    "    print(j)\n",
    "    fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_fingerprints = []\n",
    "drug_targets      = []\n",
    "drug_weights      = []\n",
    "\n",
    "\n",
    "for i in range(sample_size):\n",
    "    fingerprint_holder = [0]* fingerprint_size\n",
    "    drug_fingerprints.append(fingerprint_holder)\n",
    "    \n",
    "for i in range(sample_size):\n",
    "    target_holder = [0]* targets_num\n",
    "    drug_targets.append(target_holder)\n",
    "\n",
    "for i in range(sample_size):\n",
    "    weight_holder = [0]* weights_num\n",
    "    drug_weights.append(weight_holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_data(drug_weights_fh, drug_weights, weights_num)\n",
    "populate_data(drug_targets_fh, drug_targets, targets_num)\n",
    "populate_data(drug_fingerprints_fh, drug_fingerprints, fingerprint_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_fingerprints = np.array(drug_fingerprints)\n",
    "drug_targets      = np.array(drug_targets)\n",
    "drug_weights      = np.array(drug_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tensorflow/tpu/blob/master/models/official/resnet/resnet_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **TensorFlow** graph consists of the following parts:\n",
    "\n",
    "* **Placeholder** variables used for inputting data to the graph.\n",
    "* **Variables** that are going to be optimized so as to make the convolutional network perform better.\n",
    "* The mathematical formulas for the convolutional network.\n",
    "* **Cost function** be used to guide the optimization of the variables.\n",
    "* **Optimization** method which updates the variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, fingerprint_size],name = \"In_Flat_Drug_Fingerprint\")\n",
    "\n",
    "drug_image = tf.reshape(x, [-1, fingerprint_width, fingerprint_width, num_channels], name=\"Drug_Image_32x32\")\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, targets_num],name='True_Labels')\n",
    "\n",
    "cross_entropy_weights = tf.placeholder(tf.float32, [None, weights_num],name = \"Cross_Entropy_Weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05), name=\"Weights\")\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]), name=\"Biases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK ARCHITECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/ResNetPic.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Description\n",
    "*  **conv1** (7x7 conv, 64,/2) -> ***filter_size***=7, ***out_channels***=64, ***stride***=2\n",
    "*  **pooling layer** ***stride***=2\n",
    "*  **block1** layers 6x[(3x3 con,64,)] -> 6 conv layers with:    ***filter_size***=3, ***out_channels***=64, ***stride***=1\n",
    "*  **block2** layers 8x[(3x3 con,128,)] -> 8 conv layers with:   ***filter_size***=3, ***out_channels***=128, ***stride***=1\n",
    "*  **block3** layers 12x[(3x3 con,256,)] -> 12 conv layers with: ***filter_size***=3, ***out_channels***=265, ***stride***=1 \n",
    "*  **block4** layers 6x[(3x3 con,512,)] -> 6 conv layers with:   ***filter_size***=3, ***out_channels***=512, ***stride***=1\n",
    "* **average pooling**\n",
    "* **fully connected layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difficulty: Shortcut Connection (FIRST OROGINAL IMPLEMENTATION)\n",
    "The identity shortcuts can be directly used when the input and output are of the same dimensions (solid line shortcuts on the graph above). When the dimension increase, we have two options:\n",
    "<br>\n",
    "* (A) the shortcut still performs identity mapping with extra zero passed for increasing dimensions,\n",
    "* (B) the shortcut is used to match dimensions (done by 1x1 convolution)\n",
    "<br>\n",
    "<br>\n",
    "For both options, when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/better_residue.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/two_res_unit.png\" alt=\"Drawing2\" style=\"width:400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info about Convolution layer API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.nn.conv2d` function from TensorFlow API\n",
    "<br>\n",
    "<br>\n",
    "`tf.nn.conv2d`(\n",
    "<br>\n",
    "    input,\n",
    " <br>\n",
    "    filter,\n",
    "    <br>\n",
    "    strides,\n",
    "    <br>\n",
    "    padding,\n",
    "    <br>\n",
    "    use_cudnn_on_gpu=True,\n",
    "    <br>\n",
    "    data_format='NHWC',\n",
    "    <br>\n",
    "    dilations=[1, 1, 1, 1],\n",
    "    <br>\n",
    "    name=None\n",
    ")\n",
    "<br>\n",
    "<br>\n",
    "Computes a 2-D convolution given 4-D input and filter tensors.\n",
    "<br>\n",
    "<br>\n",
    "Given an input tensor of shape `[batch, in_height, in_width, in_channels]` and a filter / kernel tensor of shape `[filter_height, filter_width, in_channels, out_channels]`, this op performs the following:\n",
    "<br>\n",
    "<br>\n",
    "* Flattens the filter to a 2-D matrix with shape `[filter_height * filter_width * in_channels, output_channels]`.\n",
    "* Extracts image patches from the input tensor to form a virtual tensor of shape `[batch, out_height, out_width, filter_height * filter_width * in_channels]`.\n",
    "* For each patch, right-multiplies the filter matrix and the image patch vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input,              # previous layer in the network\n",
    "                   filter_size,        # size of a filer, width=height=size\n",
    "                   in_channels,        # number of channels in the input layer\n",
    "                   out_channels,       # number of channels in the output layer, aka number of filers\n",
    "                   stride = 1):        # strides = [1,stride, stride, 1]\n",
    "    \n",
    "    #Shape of the filter weights for convolution\n",
    "    shape = [filter_size, filter_size, in_channels, out_channels]\n",
    "    \n",
    "    #Create new weights = new filters of specified dimensions\n",
    "    weights = new_weights(shape = shape)\n",
    "    \n",
    "    #Create new biases, one for each filter\n",
    "    biases = new_biases(length = out_channels)\n",
    "    \n",
    "    #Create a new TensorFlow operation for convolution.\n",
    "    layer = tf.nn.conv2d(input = input, filter = weights, strides = [1, stride, stride, 1],\n",
    "                         padding=('SAME' if stride == 1 else 'VALID'), name = \"CONV\")\n",
    "    \n",
    "    layer = layer + biases\n",
    "    \n",
    "    return layer   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info about Max Pooling layer API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.nn.max_pool`(\n",
    "<br>\n",
    "    value,\n",
    "    <br>\n",
    "    ksize,\n",
    "    <br>\n",
    "    strides,\n",
    "    <br>\n",
    "    padding,\n",
    "    <br>\n",
    "    data_format='NHWC',\n",
    "    <br>\n",
    "    name=None\n",
    ")\n",
    "<br>\n",
    "* `value`: A 4-D Tensor of the format specified by data_format.\n",
    "* `ksize`: A list or tuple of 4 ints. The size of the window for each dimension of the input tensor.\n",
    "* `strides`: A list or tuple of 4 ints. The stride of the sliding window for each dimension of the input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_pooling_layer(input,dim_ksize, stride):\n",
    "    \n",
    "    layer = tf.nn.max_pool(value=input,ksize=[1, dim_ksize, dim_ksize, 1],strides=[1, stride, stride, 1],\n",
    "                           padding='SAME', name = \"POOLING_LAYER\")\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_NORM_DECAY = 0.9\n",
    "BATCH_NORM_EPSILON = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm_and_RELU(inputs,axis=3, relu = True):\n",
    "    \n",
    "    # axis= 3 because input's format is [num_images, img_height, img_width, num_channels]   \n",
    "    layer = tf.layers.batch_normalization(inputs=inputs,axis=axis,center=True,\n",
    "                                          scale=True,training=True, fused=True)\n",
    "    if relu:\n",
    "        layer = tf.nn.relu(layer) \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORIGINAL IMPLEMENTATION OF THE RESIDUAL UNIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_unit(inputs,filter_size,in_channels,out_channels, strides,use_projection=False):\n",
    "    \n",
    "    shortcut = inputs\n",
    "    \n",
    "    if use_projection:\n",
    "        kernel = 1\n",
    "        shortcut = new_conv_layer(input=inputs,filter_size = kernel,in_channels= in_channels,\n",
    "                                  out_channels = out_channels,stride = 1)\n",
    "        print(shortcut)\n",
    "        shortcut = batch_norm_and_RELU(shortcut, relu = False)\n",
    "    \n",
    "    inputs = new_conv_layer(input=inputs,filter_size = filter_size,in_channels = in_channels,\n",
    "                            out_channels = out_channels,stride = 1)\n",
    "    print(inputs)\n",
    "    inputs = batch_norm_and_RELU(inputs, relu = True)\n",
    "    \n",
    "    inputs = new_conv_layer(input=inputs,filter_size = filter_size,in_channels = in_channels,\n",
    "                            out_channels = out_channels,stride = 1)\n",
    "    \n",
    "    inputs = batch_norm_and_RELU(inputs, relu = False)\n",
    "    \n",
    "    return tf.nn.relu(inputs + shortcut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_group(inputs, blocks,filter_size, in_channels,out_channels, strides, name):\n",
    "    \n",
    "    # Only the first block per block_group uses projection shortcut and strides.\n",
    "    inputs = residual_unit(inputs, filter_size, in_channels, out_channels,strides ,use_projection = True)\n",
    "    \n",
    "    for _ in range(1, blocks):\n",
    "        inputs = residual_unit(inputs, filter_size, in_channels, out_channels, 1, use_projection = False)\n",
    "    \n",
    "    return tf.identity(inputs, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Architecture of 34-layer residual neural network:\n",
    "*  **conv1** (7x7 conv, 64,/2) -> ***filter_size***=7, ***out_channels***=64, ***stride***=2\n",
    "*  **pooling layer** ***stride***=2\n",
    "*  **block1** layers 6x[(3x3 con,64,)] -> 6 conv layers with:    ***filter_size***=3, ***out_channels***=64, ***stride***=1\n",
    "*  **block2** layers 8x[(3x3 con,128,)] -> 8 conv layers with:   ***filter_size***=3, ***out_channels***=128, ***stride***=1\n",
    "*  **block3** layers 12x[(3x3 con,256,)] -> 12 conv layers with: ***filter_size***=3, ***out_channels***=265, ***stride***=1 \n",
    "*  **block4** layers 6x[(3x3 con,512,)] -> 6 conv layers with:   ***filter_size***=3, ***out_channels***=512, ***stride***=1\n",
    "* **average pooling**\n",
    "* **fully connected layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT\n",
    "**Image** of shape `fingerprint_size` by `fingerprint_size` and `num_channels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = new_conv_layer(input = drug_image ,filter_size=7,in_channels =1,out_channels=64, stride=2)\n",
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = batch_norm_and_RELU(conv1)\n",
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_layer = new_pooling_layer(input= conv1, dim_ksize = 3,stride = 2)\n",
    "pooling_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETERS OF THE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_size_par = 3\n",
    "\n",
    "block_1_in_channels  = 64\n",
    "block_1_out_channels = 64\n",
    "num_blocks_1         = 3\n",
    "\n",
    "block_2_in_channels  = 64\n",
    "block_2_out_channels = 128\n",
    "num_blocks_2         = 4\n",
    "\n",
    "block_3_in_channels  = 128\n",
    "block_3_out_channels = 256\n",
    "num_blocks_3         = 6\n",
    "\n",
    "block_4_in_channels  = 256\n",
    "block_4_out_channels = 512\n",
    "num_blocks_4         = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 1\n",
    "layers 6x[(3x3 con,64,)] -> 6 conv layers with:    ***filter_size***=3, ***out_channels***=64, \n",
    "<br>\n",
    "or 3 times residual unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1 = block_group(inputs = pooling_layer, blocks = num_blocks_1,filter_size = filter_size_par ,in_channels = block_1_in_channels,\n",
    "                     out_channels = block_1_out_channels , strides = 1, name= \"BLOCK1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 2\n",
    "layers 8x[(3x3 con,128,)] -> 8 conv layers with:    ***filter_size***=3, ***out_channels***=128, \n",
    "<br>\n",
    "or 4 times residual unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block2 = block_group(inputs = block1, blocks = num_blocks_2,filter_size = filter_size_par ,in_channels = block_2_in_channels,\n",
    "                     out_channels = block_2_out_channels , strides = 2, name= \"BLOCK2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 3\n",
    "layers 12 x[(3x3 con,256,)] -> 12 conv layers with:    ***filter_size***=3, ***out_channels***=256, \n",
    "<br>\n",
    "or 6 times residual unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block3 = block_group(inputs = block2, blocks = num_blocks_3,filter_size = filter_size_par ,in_channels = block_3_in_channels,\n",
    "                     out_channels = block_3_out_channels , strides = 2, name= \"BLOCK3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 4 \n",
    "layers 6x[(3x3 con,512,)] -> 6 conv layers with:    ***filter_size***=3, ***out_channels***=512, \n",
    "<br>\n",
    "or  times residual unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block4 = block_group(inputs = block3, blocks = num_blocks_4,filter_size = filter_size_par ,in_channels = block_4_in_channels,\n",
    "                     out_channels = block_4_out_channels , strides = 2, name= \"BLOCK3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAX POOLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.layers.average_pooling2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
